import cv2
import mediapipe as mp
import pyautogui
import numpy as np

# Initialize mediapipe hands and drawing modules
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

# Initialize video capture
cap = cv2.VideoCapture(0)

# Set the screen size for scaling mouse movement
screen_width, screen_height = pyautogui.size()

# Variable to track the state for scrolling and clicks
scrolling = False
left_click_triggered = False
right_click_triggered = False

# Helper function to calculate the distance between two landmarks
def calculate_distance(landmark1, landmark2):
    return np.linalg.norm(np.array(landmark1) - np.array(landmark2))

# Set up hand detection
with mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.7, max_num_hands=1) as hands:
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # Flip the frame horizontally for a later selfie-view display
        frame = cv2.flip(frame, 1)

        # Reduce frame size to improve performance
        frame = cv2.resize(frame, (640, 480))

        # Convert the BGR image to RGB
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # Process the frame and detect hands
        results = hands.process(rgb_frame)

        # Access the landmarks if a hand is detected
        if results.multi_hand_landmarks:
            hand_landmarks = results.multi_hand_landmarks[0]
            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            # Extract landmarks into a numpy array for easier manipulation
            landmarks = np.array([(lm.x, lm.y) for lm in hand_landmarks.landmark])

            index_finger_tip = landmarks[8]
            thumb_tip = landmarks[4]
            middle_finger_tip = landmarks[12]

            # Convert normalized coordinates to pixel values
            height, width, _ = frame.shape
            x = int(index_finger_tip[0] * width)
            y = int(index_finger_tip[1] * height)

            # Scale the coordinates to the screen size
            mouse_x = int(x * screen_width / width)
            mouse_y = int(y * screen_height / height)

            # Move the mouse to the calculated coordinates
            pyautogui.moveTo(mouse_x, mouse_y)

            # Calculate distances between landmarks for gestures
            distance_thumb_index = calculate_distance(landmarks[8], landmarks[4])  # Thumb & index finger
            distance_thumb_middle = calculate_distance(landmarks[4], landmarks[12])  # Thumb & middle finger
            distance_index_middle = calculate_distance(landmarks[8], landmarks[12])  # Index & middle finger

            # Left-click: Index finger and thumb close together
            if distance_thumb_index < 0.04 and not left_click_triggered:
                pyautogui.click()
                left_click_triggered = True
            elif distance_thumb_index >= 0.04:
                left_click_triggered = False

            # Right-click: Middle finger and thumb close together
            if distance_thumb_middle < 0.04 and not right_click_triggered:
                pyautogui.rightClick()
                right_click_triggered = True
            elif distance_thumb_middle >= 0.04:
                right_click_triggered = False

            # Scroll: Peace sign (index and middle fingers extended, thumb away)
            # To avoid conflict, check that thumb is not involved (not close to index/middle)
            if distance_index_middle > 0.06 and distance_thumb_index > 0.05 and distance_thumb_middle > 0.05:
                if not scrolling:
                    scrolling = True
                    initial_y = y
                current_scroll = initial_y - y
                pyautogui.scroll(int(current_scroll / 2))  # Reduce scroll speed
            else:
                scrolling = False

        # Display the frame with hand landmarks
        cv2.imshow("Virtual Mouse", frame)

        # Exit the loop if the 'q' key is pressed
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

# Release the capture and close any OpenCV windows
cap.release()
cv2.destroyAllWindows()
